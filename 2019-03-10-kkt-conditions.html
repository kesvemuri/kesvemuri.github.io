---
title: KKT conditions
author: ''
date: '2019-03-10'
slug: kkt-conditions
categories:
  - Convex Optimization
tags: []
subtitle: ''
---



<blockquote>
<p>Note: we closely follow the presentation in the textbook by Boyd and Vandenberghe.</p>
</blockquote>
<p>In this post, we begin by considering the general optimization problem: <span class="math display">\[
\begin{alignat*}{3}
&amp;\text{minimize} \quad &amp;&amp; f_0(x) \\[5px]
&amp;\text{subject to} &amp;&amp; f_i(x)\le 0\,, \quad &amp;&amp; i=1,\ldots,m \\[5px]
&amp; &amp;&amp; h_j(x)=0\,, \quad &amp;&amp; j=1,\ldots,p\,
\end{alignat*}
\]</span> with <span class="math inline">\(x\in \mathbb{R}^n\)</span>. From elementary calculus, we know that relative extrema of a differentiable function <span class="math inline">\(f(x)\)</span> can be identified by solving for those <span class="math inline">\(x\)</span> that satisfy the (necessary) first-order condition <span class="math inline">\(f&#39;(x) = 0\)</span>; furthermore, this condition is sufficient if <span class="math inline">\(f\)</span> is convex. The Karush-Kuhn-Tucker (KKT) conditions serve a similar purpose in the constrained optimization setting.</p>
<div id="lagrange-dual-function" class="section level3">
<h3>Lagrange dual function</h3>
<p>We need to introduce the concept of duality and lagrange multipliers before we proceed. The basic idea is to handle the problem’s constraints by incorporating them into the objective in such a way that penalizes points <span class="math inline">\(x\)</span> that are infeasible.</p>
<hr />
<p>Consider the following somewhat trivial one-dimensional example: <span class="math display">\[
\begin{alignat*}{2}
&amp;\text{minimize} \quad &amp;&amp; f(x)=\frac{1}{8}\big(x-5 \big)^2 - 4 \\[5px]
&amp;\text{subject to} \quad &amp;&amp; x \le 2\,\,.
\end{alignat*}
\]</span> For any fixed <span class="math inline">\(\lambda &gt; 0\)</span>, we can replace the “hard barrier” constraint with a “soft” constraint and obtain the crude simplification:</p>
<p><span class="math display">\[
\begin{alignat*}{4}
&amp;\text{minimize} \quad &amp;&amp; \tilde{f}(x)= f(x) + 
\begin{cases}
0,  &amp; x\le 2\\[5px]
\infty,  &amp;x&gt;2
\end{cases} \\[10px]
&amp; &amp;&amp; \downarrow \\[15px]
&amp;\text{minimize} \quad &amp;&amp; L(x,\lambda) = f(x) + \lambda(x-2)
\end{alignat*}
\]</span> Basically, if the global optimal point of the objective function is infeasible (which it is in this case), we would hope that we can select <span class="math inline">\(\lambda\)</span> large enough so that the <u>penalty</u> of straying into infeasible territory (<span class="math inline">\(x &gt; 2\)</span> here) will overwhelm the force of <span class="math inline">\(f\)</span> and push the optimal point of the augmented function <span class="math inline">\(L\)</span> into the feasible set. Below is an interactive plot demonstrating this intuition.</p>
<iframe src="https://www.desmos.com/calculator/cda9mvcwcg?embed" width="500px" height="500px" style="border: 1px solid #ccc" frameborder="0">
</iframe>
<p>The feasible region <span class="math inline">\(\{x\le 2\}\)</span> is shaded in <span style="color:green">green</span>. The <span style="color:red">red</span> curve <span class="math inline">\(L(x, \lambda)\)</span> is obtained by summing the <span style="color:purple">purple</span> curve <span class="math inline">\(f(x)\)</span> and the dashed <span style="color:blue">blue</span> line <span class="math inline">\(\lambda(x-2)\)</span>. As we increase <span class="math inline">\(\lambda\)</span>, we observe that the optimal value of <span style="color:red">red</span> curve (rendered as an <span style="color:orange">orange</span> path) is always an <em>underestimate</em> of <span class="math inline">\(p^*\)</span>, the true optimal value of the original constrained problem (rendered as a horizontal <span style="color:black">black</span> line) or <strong>primal</strong> problem. Furthermore, notice that with <span class="math inline">\(\lambda^* = .75\)</span> the optimal value of <span class="math inline">\(L(x, \lambda^*)\)</span> coincides with the optimal value of the constrained problem, and at the optimizing argument <span class="math inline">\(x^*\)</span>, <span class="math inline">\(L&#39;(x, \lambda^*) \mid_{_{x=x^*}}\,\,=0\)</span>. This is no coincidence and we will return to this point in a moment. But intuitively, <u>the action of the lagrange multiplier <span class="math inline">\(\lambda\)</span> is to “roll” the graph of the objective function in such a way so that the new unconstrained optimum coincides with the original constrained optimum.</u></p>
<hr />
<p>Let’s generalize the construction above and apply it to the original problem. We define the <strong>Lagrangian</strong> for <span class="math inline">\(\lambda \succeq 0\)</span> as <span class="math display">\[
L(x, \lambda, \nu) \doteq f_0(x)+\sum_{i=1}^m \lambda_i\,f_i(x) + \sum_{j=1}^p \nu_j\, h_i(x)
\]</span> where <span class="math inline">\(\lambda, \nu\)</span> are known as Lagrange multipliers, and the <strong>dual function</strong> is defined as <span class="math display">\[
g(\lambda, \nu) \doteq \inf_x \;\; L(x,\lambda,\nu) 
\]</span> where this infimum is taken over the domain of the original problem (i.e. the set of <span class="math inline">\(x\)</span> for which all <span class="math inline">\(f_i, h_j\)</span> are defined). For feasible points, <span class="math inline">\(L(\tilde{x},\lambda,\nu) \le f_0(\tilde{x})\)</span> since we will have <span class="math inline">\(f_i(\tilde{x}) \le 0\)</span> and <span class="math inline">\(h_j(\tilde{x}) = 0\)</span> for all <span class="math inline">\(i\)</span> and <span class="math inline">\(j\)</span>, and we see that <span class="math display">\[
g(\lambda, \nu) \le \inf_{\tilde{x} \text{ feasible}} L(\tilde{x}, \lambda, \nu) 
\le \inf_{\tilde{x} \text{ feasible}} f_0(\tilde{x}) = p^* \tag{*}
\]</span> where <span class="math inline">\(p^*\)</span> is the optimal primal value. So for every setting of <span class="math inline">\(\lambda \succeq 0\)</span> and <span class="math inline">\(\nu\)</span>, the dual function supplies a lower bound on the optimal primal value. It is natural to then ask for the <em>best possible lower bound</em> that one can obtain using the dual function; this leads to the following <strong>dual problem</strong>: <span class="math display">\[
\begin{alignat*}{2}
&amp;\text{maximize} \quad &amp;&amp; g(\lambda, \nu) \\[5px]
&amp;\text{subject to} \quad &amp;&amp; \lambda \succeq 0\,\,.
\end{alignat*}
\]</span> This is always a <u> convex problem </u> since the dual function <span class="math inline">\(g(\lambda, \nu)\)</span> is defined as an infimum over affine functions in <span class="math inline">\(\lambda, \nu\)</span>. So we can obtain useful bounds using this duality technique even if the original problem is non-convex.</p>
<p>In the interactive graphic above, we can see that the optimal dual value, say <span class="math inline">\(d^*\)</span> is in fact equal to the optimal primal value <span class="math inline">\(p^*\)</span> (the orange curve and black line touch). We always have that <span class="math inline">\(d^* \le p^*\)</span> by taking supremum in <span class="math inline">\((^*)\)</span>, but the if it turns out that primal and dual optimal values satisfy <span class="math inline">\(d^* = p^*\)</span>, we say that <strong>strong duality</strong> holds.</p>
<!-- ### Strong duality -->
<!-- Since $g(\lambda, \nu) \le p^*$ for all values of the Lagrange multipliers, we always have that $d^* \le p^*$ or so-called <u>weak duality</u>. Recall that we can write $d^*$ as follows -->
<!-- $$ -->
<!-- d^* = \sup_{\lambda \succeq 0\,;\,\nu} \inf_x \;L(x, \lambda, \nu) -->
<!-- $$ -->
<!-- and, perhaps somewhat unexpectedly, we can express $p^*$ as  -->
<!-- $$ -->
<!-- p^* = \inf_x \sup_{\lambda \succeq 0\,; \,\nu} \; L(x, \lambda, \nu) -->
<!-- $$ -->
<!-- since  -->
<!-- $$ -->
<!-- \sup_{\lambda \succeq 0\,; \,\nu} \; L(x, \lambda, \nu) = \sup_{\lambda \succeq 0\,; \,\nu} \left[ f_0(x)+\sum_{i=1}^m \lambda_i\,f_i(x) + \sum_{j=1}^p \nu_j\, h_i(x) \right] =  -->
<!-- \begin{cases} -->
<!-- f_0(x) \quad & \text{for all }\;i,j:\;f_i(x)\le 0, \;h_j(x) = 0  \\[10px] -->
<!-- \infty \quad & \text{otherwise} -->
<!-- \end{cases} -->
<!-- $$ -->
<!-- so subsequently taking infimum over $x$ effectively restricts attention to the first branch of the conditional above which encodes precisely the feasible set. Therefore <u>strong duality</u>, the condition $d^* = p^*$, can be interpreted as a statement about the order-independence of taking supremum and infimum: -->
<!-- $$ -->
<!-- \sup_{\lambda \succeq 0\,;\,\nu} \inf_x \;L(x, \lambda, \nu) = \inf_x \sup_{\lambda \succeq 0\,; \,\nu} \;  -->
<!-- L(x, \lambda, \nu) -->
<!-- $$ -->
<!-- The "less than" directed inequality $\le$ always holds above, and is a specific instance of what is more generally known as the _max-min inequality_.  -->
<!-- That's all well and good, but how do we know when strong duality will be achieved? One such "constraint qualification" is __Slater's condition__: if the primal problem is convex, i.e. of the form  -->
<!-- $$ -->
<!-- \begin{alignat*}{3} -->
<!-- &\text{minimize} \quad && f_0(x) \\[5px] -->
<!-- &\text{subject to} && f_i(x)\le 0\,, \quad && i=1,\ldots,m \\[5px] -->
<!-- & && Ax=b\,, \quad && A\in \mathbb{R}^{p\times n}, b\in \mathbb{R}^p -->
<!-- \end{alignat*} -->
<!-- $$ -->
<!-- with $f_0, f_1,\ldots,f_m$ convex, <u> and </u> there is a point $\tilde{x}$ such that for all $i$ the inequality constraints are strict $f_i(\tilde{x}) < 0$, then strong duality holds. We refer the reader to p.234 in Boyd for a proof.  -->
</div>
<div id="kkt-conditions" class="section level3">
<h3>KKT conditions</h3>
<p>Now we will assume that the functions <span class="math inline">\(f_0, f_1, \ldots, f_m\)</span> and <span class="math inline">\(h_1, \ldots, h_p\)</span> are differentiable. We list the KKT conditions first and then contextualize them. For any <span class="math inline">\(\tilde{x}, (\tilde{\lambda}, \tilde{\nu})\)</span> the conditions are: <span class="math display">\[
\begin{alignat}{2}
f_i(\tilde{x}) &amp;\le 0,  \quad &amp;&amp;i = 1, \ldots, m \\[5px]
h_j(\tilde{x}) &amp;= 0, \quad &amp;&amp;j = 1, \ldots, p \\[5px]
\tilde{\lambda}_i &amp;\ge 0, \quad &amp;&amp;i = 1,\ldots, m \\[5px]
\tilde{\lambda}_i f_i(\tilde{x}) &amp;= 0, \quad &amp;&amp;i = 1,\ldots, m \\[5px]
\nabla f_0(\tilde{x}) + \sum_{i=1}^m \tilde{\lambda}_i \nabla f_i(\tilde{x}) + \sum_{j=1}^p \tilde{\nu}_j\nabla h_j(\tilde{x}) &amp;= 0\,\,.
\end{alignat}
\]</span></p>
<ul>
<li>The <u>first two</u> conditions are primal feasibility of <span class="math inline">\(\tilde{x}\)</span>.</li>
<li>The <u>third </u> condition is dual feasibility of <span class="math inline">\(\tilde{\lambda}\)</span>.</li>
<li>The <u>fourth </u> condition is what is known as <em>complementary slackness</em>; basically, if the unconstrained optimum does not satisfy <span class="math inline">\(f_i \le 0\)</span> (i.e. the constraint does have an impact on the location of the optimum) then the constraint should be <em>active</em>, <span class="math inline">\(f_i = 0\)</span>, at the constrained optimum. (From the graphic above, the unconstrained optimal point does not satisfy the constraint, so the constraint is active at the constrained optimum.) On the other hand, if the unconstrained optimum already satisfies <span class="math inline">\(f_i \le 0\)</span>, then this constraint isn’t necessary and we don’t need to “roll the objective” in this direction, which means the corresponding Lagrange multiplier is 0.</li>
<li>The <u> fifth </u> condition asserts that the derivative of the Lagrangian (i.e. the “rolled” objective) is 0 at the constrained optimum: <span class="math inline">\(\nabla L(x, \tilde{\lambda}, \tilde{\nu}) \mid_{_{x=x^*}}\,\,=0\)</span>. This is precisely what we observed in the graphic above.</li>
</ul>
<p>So the logic goes as follows…</p>
<hr />
<p><strong>Theorem:</strong></p>
<ol style="list-style-type: decimal">
<li>If <span class="math inline">\(x^*, (\lambda^*, \nu^*)\)</span> is a pair of primal and dual optimal points with zero duality gap (<span class="math inline">\(d^* = p^*\)</span>), then the KKT conditions hold for this pair.</li>
<li>If the primal problem is convex, i.e. if all the <span class="math inline">\(f_i\)</span> are convex and the <span class="math inline">\(h_j\)</span> are affine, then the KKT conditions holding for the pair <span class="math inline">\(\tilde{x}, (\tilde{\lambda}, \tilde{\nu})\)</span> is sufficient for this pair of points to be primal and dual optimal (with zero duality gap).</li>
</ol>
<hr />
<blockquote>
<p><em>Proof.</em> If <span class="math inline">\(x^*, (\lambda^*, \nu^*)\)</span> are primal and dual optimal, then in particular, they must be primal and dual feasible, so the first three KKT conditions hold. To verify complementary slackness, notice that feasibility together with the assumption of zero duality gap implies that <span class="math display">\[
\begin{align*}
f_0(x^*) &amp;= g(\lambda^*, \nu^*) \\[5px]
&amp;= \inf_x \; \left[ f_0(x)+\sum_{i=1}^m \lambda^*_i\,f_i(x) + \sum_{j=1}^p \nu^*_j\, h_j(x) \right] \\[5px]
&amp;\le f_0(x^*)+\underbrace{\sum_{i=1}^m \lambda^*_i\,f_i(x^*)}_{\le 0} + \underbrace{\sum_{j=1}^p \nu^*_j\, h_j(x^*)}_{=0} \\[5px]
&amp;\le f_0(x^*)
\end{align*}
\]</span> so the inequalities must be equalities, and therefore <span class="math inline">\(\lambda_i^*f_i(x^*) = 0\)</span> for all <span class="math inline">\(i=1,\ldots,m\)</span>. This gives the fourth KKT condition. To verify that the fifth KKT condition holds, notice that since the inequality in the third line above is actually an equality, <span class="math inline">\(x^*\)</span> is a minimizer of the Lagrangian <span class="math inline">\(L(x, \lambda^*, \nu^*)\)</span> so the derivative of the Lagrangian must be 0 at <span class="math inline">\(x^*\)</span>: <span class="math display">\[
\nabla f_0(x^*) + \sum_{i=1}^m \lambda^*_i \nabla f_i(x^*) + \sum_{j=1}^p \nu^*_j \nabla h_j(x^*) = 0\,.
\]</span> Now for part 2 of the theorem; suppose that the primal problem is convex. The first three feasibility KKT conditions imply that the Lagrangian <span class="math inline">\(L(x, \tilde{\lambda}, \tilde{\nu})\)</span> is convex. Therefore, the fifth KKT condition <span class="math inline">\(\nabla L(\tilde{x}, \tilde{\lambda}, \tilde{\nu}) = 0\)</span>, implies that <span class="math inline">\(\tilde{x}\)</span> is the minimizer of the Lagrangian: <span class="math display">\[
\begin{alignat*}{2}
\tilde{x} &amp;= \arg\inf_x \;L(x, \tilde{\lambda}, \tilde{\nu}) \\[15px]
\implies \quad \quad g(\tilde{\lambda}, \tilde{\nu})  &amp;= \inf_x \; L(x, \tilde{\lambda}, \tilde{\nu}) \\[5px]
&amp;= L(\tilde{x}, \tilde{\lambda}, \tilde{\nu}) \\[5px]
&amp;= f_0(\tilde{x}) + \sum_{i=1}^m \tilde{\lambda}_i f_i(\tilde{x}) + \sum_{j=1}^p \tilde{\nu}_j h_j(\tilde{x}) \\[5px]
&amp;= f_0(\tilde{x})
\end{alignat*}
\]</span> where we used the fourth KKT condition (complementary slackness), along with the third KKT condition, to conclude the last equality. From here, we see that the pair <span class="math inline">\(\tilde{x}, (\tilde{\lambda}, \tilde{\nu})\)</span> has zero duality gap and are therefore primal and dual optimal points respectively.</p>
</blockquote>
<p><br> <u>Part 2 of the theorem is especially important.</u> Most convex optimization algorithms can be interpreted as iterative methods for solving the KKT system.</p>
</div>
<div id="constraint-qualification" class="section level3">
<h3>Constraint qualification</h3>
<p>If the problem of interest is convex, i.e. of the form <span class="math display">\[
\begin{alignat*}{3}
&amp;\text{minimize} \quad &amp;&amp; f_0(x) \\[5px]
&amp;\text{subject to} &amp;&amp; f_i(x)\le 0\,, \quad &amp;&amp; i=1,\ldots,m \\[5px]
&amp; &amp;&amp; Ax = b\,, \quad &amp;&amp; A\in \mathbb{R}^{p\times n}, b\in \mathbb{R}^p
\end{alignat*}
\]</span> for <span class="math inline">\(f_0, f_1, \ldots, f_m\)</span> convex, then when can we be sure that the duality gap is zero and conclude from part 1 of the theorem that the KKT conditions hold for any primal and dual optimal pair?</p>
<p>One so-called “constraint qualification” is <strong>Slater’s condition</strong>: if there is a point <span class="math inline">\(\tilde{x}\)</span> in the interior of the domain of <span class="math inline">\(f_0\)</span> for which the inequality constraints hold with strict inequality and the equality constraints hold, <span class="math display">\[f_i(\tilde{x}) &lt; 0 \quad \text{for all }\;i = 1,\ldots,m, \quad \quad A\tilde{x} = b\]</span> then strong duality holds (assuming the problem is convex). A proof of this result can be found on page 235 of Boyd. It is worth noting that this condition is almost always met in practice, so it is safe to say that strong duality usually holds for convex problems.</p>
</div>
